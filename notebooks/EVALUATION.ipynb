{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e425461f-bffd-4812-b2cf-2f9c08363b21",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "This notebook evaluates the trained Faster R-CNN ResNet-101 model on the 153-image test set using the TensorFlow Object Detection API evaluation script. Model performance is assessed using COCO evaluation metrics, with a particular focus on mean Average Precision (mAP) at IoU thresholds of 0.50 and 0.75.\n",
    "\n",
    "The evaluation runs once on the final checkpoint (step 20,000) to measure generalization performance on completely unseen data.\n",
    "\n",
    "### What is Evaluation?\n",
    "\n",
    "**Evaluation** means testing the trained model on the **test set** (10% of our data that was NOT used for training) to measure:\n",
    "- **Map @ IoU 0.5** - How often the model correctly detects animals with at least 50% bounding box overlap\n",
    "- **Map @ IoU 0.75** - How often the model correctly detects animals with at least 75% bounding box overlap (stricter)\n",
    "- **mAP (mean Average Precision)** - Overall detection accuracy across all three species\n",
    "- **Validation Loss** - How well the model performs on unseen data (compared to training loss)\n",
    "\n",
    "### Why Evaluation is Critical\n",
    "\n",
    "Training loss only tells us how well the model learned the training images. It could be \"memorizing\" instead of truly learning. Evaluation metrics tell us if the model can generalize to NEW images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f59628b5-3b3a-4cae-84b2-af33089e84b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "/* Wrap long code and outputs */\n",
       "pre, code { \n",
       "  white-space: pre-wrap !important;\n",
       "  word-wrap: break-word !important;\n",
       "}\n",
       "\n",
       "/* Extra: make code smaller only when printing */\n",
       "@media print {\n",
       "  pre, code { font-size: 9pt !important; }\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "/* Wrap long code and outputs */\n",
    "pre, code { \n",
    "  white-space: pre-wrap !important;\n",
    "  word-wrap: break-word !important;\n",
    "}\n",
    "\n",
    "/* Extra: make code smaller only when printing */\n",
    "@media print {\n",
    "  pre, code { font-size: 9pt !important; }\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacfbd5e-5112-480c-8daf-fa2c0d5995b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6384dc2-8600-4576-8b14-625ef29b241b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n",
      "Python interpreter: C:\\Users\\MSC1\\anaconda3\\envs\\Env-7144COMP\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Python interpreter: {sys.executable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ac2d50-80c6-4074-a4dc-1aa4f9d9409a",
   "metadata": {},
   "source": [
    "## Configuration Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89323c8a-169e-4d26-987a-ec61e5c73997",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation paths configured.\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = r\"C:\\Users\\MSC1\\Desktop\\Tensorflow-Object-Detection-API\\Base\\v1\\object_detection\\training\\TF2\\faster_rcnn_output\"\n",
    "PIPELINE_CONFIG = r\"C:\\Users\\MSC1\\Desktop\\Tensorflow-Object-Detection-API\\Base\\v1\\object_detection\\training\\TF2\\training\\faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8\\pipeline.config\"\n",
    "MODEL_MAIN = r\"C:\\Users\\MSC1\\Desktop\\Tensorflow-Object-Detection-API\\models\\research\\object_detection\\model_main_tf2.py\"\n",
    "\n",
    "print(\"Evaluation paths configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85badca-0fdc-4c64-8c7d-543150deb168",
   "metadata": {},
   "source": [
    "## Configure Python Paths for TF Object Detection API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6911bf1f-9151-4fef-9220-af235bc58082",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Object Detection API paths configured.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "TFOD_ROOT = r\"C:\\Users\\MSC1\\Desktop\\Tensorflow-Object-Detection-API\\models\"\n",
    "RESEARCH_DIR = os.path.join(TFOD_ROOT, \"research\")\n",
    "SLIM_DIR = os.path.join(RESEARCH_DIR, \"slim\")\n",
    "\n",
    "for p in [RESEARCH_DIR, SLIM_DIR]:\n",
    "    if p not in sys.path:\n",
    "        sys.path.insert(0, p)\n",
    "\n",
    "os.environ[\"PYTHONPATH\"] = RESEARCH_DIR + os.pathsep + SLIM_DIR\n",
    "\n",
    "print(\"TF Object Detection API paths configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68afad1e-b2ca-4047-b8c9-40a8657e4498",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ object_detection import works!\n"
     ]
    }
   ],
   "source": [
    "from object_detection import model_lib_v2\n",
    "print(\"✅ object_detection import works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06342c99-569e-4cb2-849c-dcb3852a0eb8",
   "metadata": {},
   "source": [
    "## Run Model Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b47fde6-d6bd-4f2d-84f4-b51f69bf1381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_DIR: C:\\Users\\MSC1\\Desktop\\Tensorflow-Object-Detection-API\\Base\\v1\\object_detection\\training\\TF2\\faster_rcnn_output\n",
      "PIPELINE_CONFIG: C:\\Users\\MSC1\\Desktop\\Tensorflow-Object-Detection-API\\Base\\v1\\object_detection\\training\\TF2\\training\\faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8\\pipeline.config\n",
      "MODEL_MAIN: C:\\Users\\MSC1\\Desktop\\Tensorflow-Object-Detection-API\\models\\research\\object_detection\\model_main_tf2.py\n",
      "\n",
      "Running evaluation command:\n",
      "\n",
      "C:\\Users\\MSC1\\anaconda3\\envs\\Env-7144COMP\\python.exe C:\\Users\\MSC1\\Desktop\\Tensorflow-Object-Detection-API\\models\\research\\object_detection\\model_main_tf2.py --pipeline_config_path=C:\\Users\\MSC1\\Desktop\\Tensorflow-Object-Detection-API\\Base\\v1\\object_detection\\training\\TF2\\training\\faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8\\pipeline.config --model_dir=C:\\Users\\MSC1\\Desktop\\Tensorflow-Object-Detection-API\\Base\\v1\\object_detection\\training\\TF2\\faster_rcnn_output --checkpoint_dir=C:\\Users\\MSC1\\Desktop\\Tensorflow-Object-Detection-API\\Base\\v1\\object_detection\\training\\TF2\\faster_rcnn_output --run_once=True\n",
      "\n",
      "==== STDOUT (last 5000 chars) ====\n",
      "An error occurred: module 'importlib.metadata' has no attribute 'packages_distributions'\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.27s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.954\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.811\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.660\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.579\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.743\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.750\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750\n",
      "\n",
      "\n",
      "==== STDERR (last 5000 chars) ====\n",
      " numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W0108 00:32:08.388886 10700 deprecation.py:330] From C:\\Users\\MSC1\\anaconda3\\envs\\Env-7144COMP\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:464: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "INFO:tensorflow:Finished eval step 100\n",
      "I0108 00:32:28.085480 10700 model_lib_v2.py:966] Finished eval step 100\n",
      "INFO:tensorflow:Performing evaluation on 153 images.\n",
      "I0108 00:32:32.757014 10700 coco_evaluation.py:293] Performing evaluation on 153 images.\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0108 00:32:32.757014 10700 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.03s)\n",
      "I0108 00:32:32.789055 10700 coco_tools.py:138] DONE (t=0.03s)\n",
      "INFO:tensorflow:Eval metrics at step 20000\n",
      "I0108 00:32:34.246357 10700 model_lib_v2.py:1015] Eval metrics at step 20000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.659601\n",
      "I0108 00:32:34.289817 10700 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.659601\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.954371\n",
      "I0108 00:32:34.289817 10700 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.954371\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.811241\n",
      "I0108 00:32:34.289817 10700 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.811241\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
      "I0108 00:32:34.289817 10700 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n",
      "I0108 00:32:34.304442 10700 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.659663\n",
      "I0108 00:32:34.304442 10700 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.659663\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.579295\n",
      "I0108 00:32:34.304442 10700 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.579295\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.742852\n",
      "I0108 00:32:34.304442 10700 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.742852\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.749820\n",
      "I0108 00:32:34.304442 10700 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.749820\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
      "I0108 00:32:34.304442 10700 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
      "I0108 00:32:34.304442 10700 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.749820\n",
      "I0108 00:32:34.304442 10700 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.749820\n",
      "INFO:tensorflow:\t+ Loss/RPNLoss/localization_loss: 0.060332\n",
      "I0108 00:32:34.304442 10700 model_lib_v2.py:1018] \t+ Loss/RPNLoss/localization_loss: 0.060332\n",
      "INFO:tensorflow:\t+ Loss/RPNLoss/objectness_loss: 0.033117\n",
      "I0108 00:32:34.304442 10700 model_lib_v2.py:1018] \t+ Loss/RPNLoss/objectness_loss: 0.033117\n",
      "INFO:tensorflow:\t+ Loss/BoxClassifierLoss/localization_loss: 0.065348\n",
      "I0108 00:32:34.304442 10700 model_lib_v2.py:1018] \t+ Loss/BoxClassifierLoss/localization_loss: 0.065348\n",
      "INFO:tensorflow:\t+ Loss/BoxClassifierLoss/classification_loss: 0.088309\n",
      "I0108 00:32:34.304442 10700 model_lib_v2.py:1018] \t+ Loss/BoxClassifierLoss/classification_loss: 0.088309\n",
      "INFO:tensorflow:\t+ Loss/regularization_loss: 0.000000\n",
      "I0108 00:32:34.304442 10700 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.000000\n",
      "INFO:tensorflow:\t+ Loss/total_loss: 0.247105\n",
      "I0108 00:32:34.304442 10700 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.247105\n",
      "INFO:tensorflow:Exiting evaluation at step 20000\n",
      "I0108 00:32:34.445009 10700 model_lib_v2.py:1168] Exiting evaluation at step 20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Paths\n",
    "MODEL_DIR = r\"C:\\Users\\MSC1\\Desktop\\Tensorflow-Object-Detection-API\\Base\\v1\\object_detection\\training\\TF2\\faster_rcnn_output\"\n",
    "\n",
    "PIPELINE_CONFIG = r\"C:\\Users\\MSC1\\Desktop\\Tensorflow-Object-Detection-API\\Base\\v1\\object_detection\\training\\TF2\\training\\faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8\\pipeline.config\"\n",
    "\n",
    "MODEL_MAIN = r\"C:\\Users\\MSC1\\Desktop\\Tensorflow-Object-Detection-API\\models\\research\\object_detection\\model_main_tf2.py\"\n",
    "\n",
    "print(\"MODEL_DIR:\", MODEL_DIR)\n",
    "print(\"PIPELINE_CONFIG:\", PIPELINE_CONFIG)\n",
    "print(\"MODEL_MAIN:\", MODEL_MAIN)\n",
    "\n",
    "# Build evaluation command\n",
    "eval_command = [\n",
    "    sys.executable,\n",
    "    MODEL_MAIN,\n",
    "    f\"--pipeline_config_path={PIPELINE_CONFIG}\",\n",
    "    f\"--model_dir={MODEL_DIR}\",\n",
    "    f\"--checkpoint_dir={MODEL_DIR}\",\n",
    "    \"--run_once=True\"\n",
    "]\n",
    "\n",
    "print(\"\\nRunning evaluation command:\\n\")\n",
    "print(\" \".join(eval_command))\n",
    "\n",
    "# Run evaluation\n",
    "result = subprocess.run(eval_command, capture_output=True, text=True)\n",
    "\n",
    "print(\"\\n==== STDOUT (last 5000 chars) ====\")\n",
    "print(result.stdout[-5000:])\n",
    "\n",
    "print(\"\\n==== STDERR (last 5000 chars) ====\")\n",
    "print(result.stderr[-5000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c3c5d-b335-4dc3-a820-e42027cc9f8e",
   "metadata": {},
   "source": [
    "## Evaluation Result Summary\n",
    "The trained Faster R-CNN ResNet-101 model was evaluated on the held-out test set containing 153 images using the TensorFlow Object Detection API evaluation script. Evaluation was performed once using the final checkpoint at step 20,000 to measure generalisation performance on unseen data.\n",
    "\n",
    "### COCO Evaluation Metrics\n",
    "\n",
    "| Metric | Value | Interpretation |\n",
    "|------|------|--------------|\n",
    "| mAP@[0.50:0.95] | 0.660 | Overall detection performance across multiple IoU thresholds |\n",
    "| mAP@0.50 | 0.954 | High detection and classification performance under moderate localisation constraints |\n",
    "| mAP@0.75 | 0.811 | Strong localisation performance under stricter overlap requirements |\n",
    "| AR@100 | 0.750 | The model retrieves most ground-truth objects when up to 100 detections are allowed |\n",
    "\n",
    "### Interpretation of Results\n",
    "\n",
    "The high mAP@0.50 score indicates that the model reliably detects and classifies the three wildlife species when a moderate bounding box overlap is required. The drop in performance at IoU 0.75 is expected, as stricter overlap thresholds place higher demands on precise localisation, particularly for animals with variable poses, occlusions, and scale differences.\n",
    "\n",
    "The absence of small and medium object metrics reflects the dataset characteristics, where most annotated animals fall into the large object category. Overall, the evaluation results shows strong generalisation performance and confirm that the model has learned robust wildlife-specific features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ce18a-62de-4e50-ae6f-0fb102391ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
